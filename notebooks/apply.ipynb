{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp apply\n",
    "pass # xpython fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply preprocessing to db\n",
    "\n",
    "> API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from ifcimglib import imglmdb, utils, preprocessing, cif2lmdb\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import pickle\n",
    "import logging\n",
    "import lmdb\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import seaborn\n",
    "from sklearn.model_selection import PredefinedSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def preprocess_db_intra_image(db, preprocessed_output_path):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    if Path(preprocessed_output_path).exists():\n",
    "        Path(preprocessed_output_path).unlink()\n",
    "    \n",
    "    env = lmdb.open(preprocessed_output_path, lock=False, sync=False, map_size=cif2lmdb.map_size, subdir=False)\n",
    "    logger.info(\"Opened lmdb database %s\" % preprocessed_output_path)\n",
    "    \n",
    "    with env.begin(write=True) as txn:\n",
    "        txn.put(b'__targets__', pickle.dumps(db.targets))\n",
    "        txn.put(b'__len__', len(db).to_bytes(db.idx_byte_length, \"big\"))\n",
    "        txn.put(b'__names__', \" \".join(db.names).encode(\"utf-8\"))\n",
    "        \n",
    "        for i in trange(len(db)):\n",
    "            x, m, _ = db.get_image(i)\n",
    "            x = x.astype(numpy.float32)\n",
    "            x = preprocessing.log_transform(x, m, [1])\n",
    "            x = preprocessing.min_max_normalize(x, m, \"clip\")\n",
    "            x = preprocessing.crop_and_pad_to_square(x, 70)\n",
    "            m = preprocessing.crop_and_pad_to_square(m.astype(numpy.uint8), 70).astype(bool)\n",
    "            \n",
    "            instance = cif2lmdb.get_instance(x.shape[1:], x.shape[0])\n",
    "            instance = cif2lmdb.set_instance_data(instance, x.astype(numpy.float16), m)\n",
    "            \n",
    "            txn.put(i.to_bytes(db.idx_byte_length, byteorder='big'), pickle.dumps(instance))\n",
    "    env.sync()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def aggregate_fold_stats(db_paths, cv_pkl_file):\n",
    "    preprocessed_db = imglmdb.multidbwrapper(sorted(db_paths))\n",
    "    with open(cv_pkl_file, \"rb\") as pkl:\n",
    "        test_fold, nested_test_folds = pickle.load(pkl)\n",
    "        \n",
    "    splitter = PredefinedSplit(test_fold)\n",
    "    \n",
    "    data = [{}]*splitter.get_n_splits()\n",
    "    \n",
    "    for i, (nested_test_fold, (_, test_idx)) in enumerate(zip(nested_test_folds, splitter.split())):        \n",
    "        per_pixel_stats = preprocessing.compute_per_pixel_stats(preprocessed_db, None, idx=test_idx)\n",
    "        std_per_pixel = numpy.where(per_pixel_stats[1] == 0.0, 1, per_pixel_stats[1])\n",
    "        data[i][\"outer\"] = (per_pixel_stats[0], std_per_pixel)\n",
    "        \n",
    "        nested_splitter = PredefinedSplit(nested_test_fold)\n",
    "        data[i][\"nested\"] = [{}]*nested_splitter.get_n_splits()\n",
    "        \n",
    "        for j, (train_idx, val_idx) in enumerate(nested_splitter.split()):\n",
    "            per_pixel_stats = preprocessing.compute_per_pixel_stats(preprocessed_db, None, idx=train_idx)\n",
    "            std_per_pixel = numpy.where(per_pixel_stats[1] == 0.0, 1, per_pixel_stats[1])\n",
    "            data[i][\"nested\"][j][\"train\"] = (per_pixel_stats[0], std_per_pixel)\n",
    "            \n",
    "            per_pixel_stats = preprocessing.compute_per_pixel_stats(preprocessed_db, None, idx=val_idx)\n",
    "            std_per_pixel = numpy.where(per_pixel_stats[1] == 0.0, 1, per_pixel_stats[1])\n",
    "            data[i][\"nested\"][j][\"val\"] = (per_pixel_stats[0], std_per_pixel)\n",
    "            \n",
    "    with open(os.path.splitext(cv_pkl_file)[0] + \"_stats.pkl\", \"wb\") as pkl:\n",
    "        pickle.dump(data, pkl)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23030/23030 [00:20<00:00, 1117.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for db_path in [f for f in Path(\"/home/maximl/scratch/data/wbc/\").rglob(\"*.lmdb\") if \"preprocessed\" not in str(f)]:\n",
    "    db = imglmdb.imglmdb(str(db_path))\n",
    "    preprocess_db_intra_image(db, os.path.join(*db_path.parts[:-1], \"CD45_focused_singlets_preprocessed.lmdb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71599/71599 [00:14<00:00, 4942.38it/s]\n",
      "100%|██████████| 71599/71599 [00:13<00:00, 5293.03it/s]\n",
      "100%|██████████| 65336/65336 [00:11<00:00, 5471.76it/s]\n",
      "100%|██████████| 65336/65336 [00:12<00:00, 5076.17it/s]\n",
      "100%|██████████| 32668/32668 [00:06<00:00, 5023.30it/s]\n",
      "100%|██████████| 32668/32668 [00:06<00:00, 5010.21it/s]\n",
      "100%|██████████| 65336/65336 [00:11<00:00, 5582.70it/s]\n",
      "100%|██████████| 65336/65336 [00:13<00:00, 4922.48it/s]\n",
      "100%|██████████| 32668/32668 [00:06<00:00, 5297.60it/s]\n",
      "100%|██████████| 32668/32668 [00:06<00:00, 4955.88it/s]\n",
      "100%|██████████| 65336/65336 [00:11<00:00, 5486.94it/s]\n",
      "100%|██████████| 65336/65336 [00:13<00:00, 4832.81it/s]\n",
      "100%|██████████| 32668/32668 [00:05<00:00, 5715.46it/s]\n",
      "100%|██████████| 32668/32668 [00:06<00:00, 4731.36it/s]\n",
      "100%|██████████| 68010/68010 [00:13<00:00, 4949.34it/s]\n",
      "100%|██████████| 68010/68010 [00:13<00:00, 5064.22it/s]\n",
      "100%|██████████| 67728/67728 [00:12<00:00, 5444.02it/s]\n",
      "100%|██████████| 67728/67728 [00:13<00:00, 5004.10it/s]\n",
      "100%|██████████| 33865/33865 [00:06<00:00, 5252.02it/s]\n",
      "100%|██████████| 33865/33865 [00:07<00:00, 4793.98it/s]\n",
      "100%|██████████| 67729/67729 [00:12<00:00, 5510.47it/s]\n",
      "100%|██████████| 67729/67729 [00:13<00:00, 5061.62it/s]\n",
      "100%|██████████| 33864/33864 [00:06<00:00, 5550.17it/s]\n",
      "100%|██████████| 33864/33864 [00:06<00:00, 5207.84it/s]\n",
      "100%|██████████| 67729/67729 [00:12<00:00, 5567.13it/s]\n",
      "100%|██████████| 67729/67729 [00:13<00:00, 5006.97it/s]\n",
      "100%|██████████| 33864/33864 [00:06<00:00, 5422.41it/s]\n",
      "100%|██████████| 33864/33864 [00:06<00:00, 4945.04it/s]\n",
      "100%|██████████| 29994/29994 [00:05<00:00, 5109.88it/s]\n",
      "100%|██████████| 29994/29994 [00:06<00:00, 4996.37it/s]\n",
      "100%|██████████| 93072/93072 [00:16<00:00, 5681.91it/s]\n",
      "100%|██████████| 93072/93072 [00:18<00:00, 5122.78it/s]\n",
      "100%|██████████| 46537/46537 [00:08<00:00, 5771.69it/s]\n",
      "100%|██████████| 46537/46537 [00:09<00:00, 4781.72it/s]\n",
      "100%|██████████| 93073/93073 [00:16<00:00, 5590.34it/s]\n",
      "100%|██████████| 93073/93073 [00:18<00:00, 4986.79it/s]\n",
      "100%|██████████| 46536/46536 [00:08<00:00, 5742.90it/s]\n",
      "100%|██████████| 46536/46536 [00:08<00:00, 5360.90it/s]\n",
      "100%|██████████| 93073/93073 [00:17<00:00, 5356.98it/s]\n",
      "100%|██████████| 93073/93073 [00:17<00:00, 5268.06it/s]\n",
      "100%|██████████| 46536/46536 [00:08<00:00, 5495.99it/s]\n",
      "100%|██████████| 46536/46536 [00:09<00:00, 5167.79it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_db_paths = [str(f) for f in Path(\"/home/maximl/scratch/data/wbc/\").rglob(\"*preprocessed.lmdb\")]\n",
    "cv_pkl_file = \"/home/maximl/scratch/data/wbc/samplesplit_234_nested_3fold.pkl\"\n",
    "\n",
    "data = aggregate_fold_stats(preprocessed_db_paths, cv_pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.splitext(cv_pkl_file)[0] + \"_stats.pkl\", \"rb\") as pkl:\n",
    "    data = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
